
#Written/modified by Fan Zhu z5245075
#for COMP9414 Project/assignment 3
#due 01/05/2019

'''
The code performs a minimax search algorithm with added alpha-beta pruning
to play as an AI agent in the game of Nine-Board Tic-Tac-Toe
First a function named heuristics() is used to find the utility of 
the board currently being played on.

get_moves() is created to find the most optimal move ordering for the current
board and returns a list of moves available for that board
minimax() is the minimax search algorithm with added alpha-beta pruning
it reads in the a copy of the entire 9board and evaluates the heuristics of
the 9board. using get_moves() within minimax() this gives us a move list
so the branches evaluates the stronger moves before the weaker moves for
best use of alpha-beta pruning.

The bestMoves() function initiates the search.
first the list of moves is evaluated for the current board being played on,
for each of the move, minimax() is used to find the best possible move.
minimax() at this stage in bestMoves() evaluates the next board
since the move affects the next board played by opponent.
we want the highest possible minimax() value returned, the highest value means
the move is the best move to be played.
this section is also designed so it finds the greatest first value
(using > not >=), due to the moves should be ordered by strongest to weakest
move by get_moves() already.

Finaly bestMoves() is called in AiPlay() so the best move can be returned
to the port back to server.
'''

'''
There is planned improvement to the code as it cannot beat the given AI
with the current implementation of heuristics and minimax alpha-beta seach.
Updates will be posted here. (note these updates are not actual 'Updates' but
updates to each algorithm that is satisfactory enough to be handed in)

Update 1
Updated heuristics to try and implement killer move heuristics.
the function killer_moves() returns a list if the list exists for the move depth.
get_moves() takes the list and adds it infront of the list generated by normal
heuristics so the final list has the killer moves to check first as they should be
the strongest

killer_update() function checks for the move that causes alpha-beta pruning in
the minimax() function, this move is so far the strongest move.
if the move already exists under the current move depth, e.g. move 5 on turn 9
is already a in the killer move list for turn 9
then increase the move's position in the killer move list to the front.

if alpha-beta pruning does not occur and a killer move was in the list
killer_degrade() checks for the move in the killer move dictionary and
if the move was a killer move, it is moved to the end of the list.

thus the 'strongest' move is always checked first and a higher chance to not get pruned
by alpha beta.

although the killer move heuristics is implemented, I feel it is not implemented to its full
potential as the depth of my minimax() search is shallow and the 9board has a very deep gametree.

for python if the depth, in my case atleast, were increased beyond 4, the program slows down too
much to return a response within the timeout limit.

currently code is being checked for optimisation for deeper search, or if killer heuristics is
implemented incorrectly.

Update 2:
formatted some comments and print functions
'''
import socket
import sys
import numpy as np
import random

# a board cell can hold:
#   0 - Empty
#   1 - I played here
#   2 - They played here

# the boards are of size 10 because index 0 isn't used
boards = np.zeros((10, 10), dtype="int8")
s = [".","X","O"]
curr = 0 # this is the current board to play in
prev = 0

killer_dict = {}

# print a row
# This is just ported from game.c
def print_board_row(board, a, b, c, i, j, k):
    print(" "+s[board[a][i]]+" "+s[board[a][j]]+" "+s[board[a][k]]+" | " \
             +s[board[b][i]]+" "+s[board[b][j]]+" "+s[board[b][k]]+" | " \
             +s[board[c][i]]+" "+s[board[c][j]]+" "+s[board[c][k]])

# Print the entire board
# This is just ported from game.c
def print_board(board):
    print_board_row(board, 1,2,3,1,2,3)
    print_board_row(board, 1,2,3,4,5,6)
    print_board_row(board, 1,2,3,7,8,9)
    print(" ------+-------+------")
    print_board_row(board, 4,5,6,1,2,3)
    print_board_row(board, 4,5,6,4,5,6)
    print_board_row(board, 4,5,6,7,8,9)
    print(" ------+-------+------")
    print_board_row(board, 7,8,9,1,2,3)
    print_board_row(board, 7,8,9,4,5,6)
    print_board_row(board, 7,8,9,7,8,9)
    print()
    
#check if board full
def full_board(bb):
    test = []
    
    c = 1
    while c in range(len(bb)):
        if bb[c] == 0:
            return False

        c += 1

    return True

#check heuristics of the board with week5 heuristic equation
def heuristics(board):
    ev = 0
    util_t = []
    util_t2 = []
    board_win = [[board[1], board[2], board[3]],\
                 [board[4], board[5], board[6]],\
                 [board[7], board[8], board[9]],\
                 [board[1], board[4], board[7]],\
                 [board[2], board[5], board[8]],\
                 [board[3], board[6], board[9]],\
                 [board[1], board[5], board[9]],\
                 [board[3], board[5], board[7]]]
    


    for i in range(len(board_win)):
        p_count = 0
        o_count = 0
        for j in range(len(board_win[i])):
            if board_win[i][j] == 1:
                p_count += 1
            elif board_win[i][j] == 2:
                o_count += 1

        util_t.append(p_count)
        util_t2.append(o_count)

    if 3 in util_t:
        ev = 10
    elif 3 in util_t2:
        ev = -10
    elif sum(util_t) == 0 and sum(util_t2) == 0:
        ev = 0
    else:
        x2 = util_t.count(2)
        o2 = util_t2.count(2)
        x1 = util_t.count(1)
        o1 = util_t2.count(1)

        ev = (3*x2 + x1) - (3*o2 - o1)
        
    return ev
            
        
        
    

# choose a move to play
def play():
    # print_board(boards)

    # just play a random move for now
    n = np.random.randint(1,9)
    while boards[curr][n] != 0:
        n = np.random.randint(1,9)

    # print("playing", n)
    place(curr, n, 1)
    return n

#place move on board and change current board
def place(board, num, player):
    #print(board, num, player)
    global curr
    global prev
    prev = curr
    curr = num
    boards[board][num] = player

#count the number of moves made so far on entire 9board
def move_num(board):
    count = 0
    for i in range(len(board)):
        for j in range(len(board[i])):
            if board[i][j] != 0:
                count += 1
    return count

#function to play as agent
def AiPlay():
    global curr
    board_c = boards
    m = move_num(board_c)
    n = bestMove(board_c, curr, m)

    print('The move played by agent is: ', n)
    place(curr, n, 1)
    return n

#minimax search with alpha-beta pruning
def minimax(board, num, old_num, m_num, depth, player, alpha, beta):

    #get most optimal moves based on current board's heuristics
    moves = get_moves(board, num, m_num)

    #heuristics takes into account of current board and previous board
    r = heuristics(board[num]) + heuristics(board[old_num])
    #print('*@', depth)
    if depth == 4:
        return r
    #if board is full
    if full_board(board[num]) == True:
        return 0 
    #when player is agent/max player
    if player == 1:
        for i in range(len(moves)):
            if board[num][moves[i]] == 0:
                board[num][moves[i]] = player
                value = minimax(board, moves[i], num, m_num+1, depth+1, 2, alpha, beta)
                board[num][moves[i]] = 0
                '''    
                if value > alpha:
                    alpha = value
                '''
                alpha = max(alpha, value)
                if alpha >= beta:
                    killer_update(moves[i], m_num)
                    break
                else:
                    killer_degrade(moves[i], m_num)
                
                    
        return alpha
    #when player is opponent/min player
    else:
        for i in range(len(moves)):
            if board[num][moves[i]] == 0:
                board[num][moves[i]] = player
                value = minimax(board, moves[i], num, m_num+1, depth+1, 1, alpha, beta)
                board[num][moves[i]] = 0
                '''
                if value < beta:
                    beta = value
                '''    
                beta = min(beta, value)
                if beta <= alpha:
                    killer_update(moves[i], m_num)
                    break
                else:
                    killer_degrade(moves[i], m_num)
              
        return beta
    

#check of board is empty
def empty_board(board):
    for i in range(len(board)):
        for j in range(len(board[i])):
            if board[i][j] != 0:
                return False

    return True

#update killer dictionary
def killer_update(killer_moves, m_num):
    global killer_dict
    if m_num in killer_dict.keys():
        for k, v in killer_dict.items():
            if k == m_num:
                if killer_moves in v:
                    v.insert(0, v.pop(v.index(killer_moves)))
                else:
                    v = v.append(killer_moves)
    else:
        killer_dict.update({m_num: [killer_moves]})

    pass

#degrade a bad killer move
def killer_degrade(killer_moves, m_num):
    global killer_dict
    if m_num in killer_dict.keys():
        for k, v in killer_dict.items():
            if k == m_num:
                if killer_moves in v:
                    v.append(v.pop(v.index(killer_moves)))
                    
    pass

#finds the killer moves for a given move depth 
def killer_moves(m_num):
    global killer_dict

    if m_num in killer_dict.keys():
        return killer_dict[m_num]
    else:
        return []

#returns 2nd element of a list
def elem2(L):
    return L[1]

#get most optimal move based on heurists of the current 9board
def get_moves(board, num, m_num):
    
    avail_m = []
    avail_m_sorted = []
    moves = []
    
    for i in range(len(board[num])):
        if i != 0:
            if board[num][i] == 0:
                board[num][i] = 1
                H = heuristics(board[num])
                board[num][i] = 0
                avail_m.append([i, H])
                
    #sort moves by strength
    avail_m.sort(key = elem2, reverse = True)

    for i in range(len(avail_m)):
        avail_m_sorted.append(avail_m[i][0])

    #always have killer moves tried first
    moves_temp = killer_moves(m_num) + avail_m_sorted
    
    #remove repeated moves
    for i in range(len(moves_temp)):
        if moves_temp[i] not in moves:
            moves.append(moves_temp[i])

    return moves
    #print('*&', moves)

#finds the best move to play
def bestMove(board, num, m_num):
    alpha = float("-inf")
    beta = float("inf")
    bestVal = float("-inf")

    moves = get_moves(board, num, m_num)
    for i in range(len(moves)):
        if board[num][moves[i]] == 0:
            board[num][moves[i]] == 1
            check_val = minimax(board, moves[i], num, m_num+1, 0, 1, alpha, beta)
            board[num][moves[i]] == 0

            #the best move is the one with best value from minimax search
            if check_val > bestVal:
                bestMoves = moves[i]
                bestVal = check_val

    return bestMoves
    
    


# read what the server sent us and
# only parses the strings that are necessary
def parse(string):
    if "(" in string:
        command, args = string.split("(")
        args = args.split(")")[0]
        args = args.split(",")
    else:
        command, args = string, []

    if command == "second_move":
        place(int(args[0]), int(args[1]), 2)
        return AiPlay()
    elif command == "third_move":
        # place the move that was generated for us
        place(int(args[0]), int(args[1]), 1)
        # place their last move
        place(curr, int(args[2]), 2)
        return AiPlay()
    elif command == "next_move":
        place(curr, int(args[0]), 2)
        return AiPlay()
    elif command == "win":
        print("Yay!! We win!! :)")
        return -1
    elif command == "loss":
        print("We lost :(")
        return -1
    return 0

# connect to socket
def main():
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    port = int(sys.argv[2]) # Usage: ./agent.py -p (port)

    s.connect(('localhost', port))
    while True:
        text = s.recv(1024).decode()
        if not text:
            continue
        for line in text.split("\n"):
            response = parse(line)
            if response == -1:
                s.close()
                return
            elif response > 0:
                s.sendall((str(response) + "\n").encode())

if __name__ == "__main__":
    main()
